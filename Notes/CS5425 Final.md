## MapReduce
### MapReduce过程
1. Map 映射
	- map函数将对每个元素根据特定标准映射，输出键值对
2. Shuffle (Group) 排序分组
	- 将所有键值对进行排序，并根据键值对中的键(key)进行分组，具有相同键的值会聚集在一起
3. Reduce 归约
	- reduce函数对每个键进值进行操作，将它们合并为更小的集合，reduce函数会收到(word, [1,2,3,...])形式的键值对，将值列表合并成单一的数字，例如全部相加。
### Partitioner 分区器
- 负责确定在shuffle阶段键值对应该发送给哪个reducer
- 一般情况下，分区器使用键的哈希值对reduce任务的数量取模决定reducer，用户可以自定义
- 需要确保相同的键被发送到同一个reducer
### Combiner 组合器
- 在map阶段将中间键值对合并，减少发送到reducer的键值对数量，提高效率
- 可以被看作是一个安放在map阶段的reducer
- Combiner的输出键值对必须和输入键值对有**相同的结构（键值类型）**
### 数据传输过程
1. Mapper：输入数据存储在分布式文件系统中。mapper从**本地磁盘**读取数据，处理他们，在**内存**中生成键值对并缓存。如果键值对过多，超出了可用的内存时，会被排序后写入**本地磁盘**。Mapper的输出会被**写入本地磁盘**
2. Combiner：从**本地磁盘**读取mapper的结果，处理数据的过程在**内存**中进行，输出会被写入到**本地磁盘**
3. Partitioner：发生在mapper节点上，从**本地磁盘**读取mapper或combiner的输出数据，在**内存**中处理数据，输出保存在**本地磁盘**
4. Shuffle：reducer节点会从mapper节点的**本地磁盘**中拉取自己需要的数据，通过网络发送。这些数据被保存在**内存**中，如果数据超出内存空间，则剩余的部分保存在**本地磁盘**
5. Reducer：如果未完成排序和合并，则这些操作会在**本地磁盘**进行。在内存中应用reduce函数生成输出。最后reducer的输出会被写回分布式文件系统中
### Secondary Sort
在MapReduce框架中，数据是以键值对(key-value pairs)的形式进行处理的。在这个过程中，Map阶段生成的键值对会被分组(grouped)和排序(sorted)，然后传递给Reduce阶段。默认情况下，MapReduce只会按键（key）进行排序，这称为“自然排序”。
如果我们需要以一种额外的方式对值进行排序，则这被称作为二次排序"secondary sort":
- 定义一个新的“复合键”（composite key），格式为(K1, K2)，其中K1是原始键（也称为“自然键”），K2是我们希望用于排序的变量。在这种情况下，复合键将会影响如何对数据进行分区和排序：
	- **Partitioner**: 需要自定义分区器，使其仅按K1进行分区，而不是按复合键(K1, K2)分区。这样可以保证相同的K1会被发送到同一个reducer，但是在reducer内部，数据会根据K2的值进行排序。
这样，每个reducer接收的数据就会首先根据K1分组，然后在每个组内根据K2排序，实现了二次排序的目的
## NoSQL
### Broadcast (Map) Join
1. **选择较小的数据集**：在两个需要连接的数据集中，选择较小的那个进行广播。这意味着这个数据集会被发送到集群中的每个节点，以便于本地连接操作。
2. **广播到所有节点**：所选择的较小数据集会被复制并广播到集群中的每个节点。在Spark中，这通常通过`broadcast`函数实现。
3. **本地连接**：大数据集不动，较小的数据集被广播到每个节点后，大数据集的每个分区会与本地节点上的小数据集进行连接操作。由于小数据集已经在每个节点的内存中，这大大减少了网络传输的需求，并且可以并行地在每个节点上快速完成连接。
4. **减少数据洗牌**：使用broadcast join 可以避免在网络中进行昂贵的数据洗牌操作，因为只有小数据集在节点间移动，而大数据集则保持静止。
### Reduce-side (Common) Join
Reduce side join 是在 MapReduce 编程模型中用于处理大规模数据集连接的一种机制。这种类型的 join 操作涉及到 Map 和 Reduce 两个阶段，在这个过程中，两个数据集都参与到数据的洗牌和排序过程中。这种 join 在处理两个大数据集的连接时尤其有用，因为它不需要将整个数据集加载到内存中。
以下是 Reduce side join 的基本步骤：
1. **Map 阶段**：
    - 两个数据集（比如数据集A和数据集B）都会被读取，并在 Map 阶段被处理。
    - Map 函数会对每条记录产生中间的键值对（key-value pairs）。键通常是两个数据集中用于连接的共同字段，而值则是包含原始数据和数据来源标识（例如来自数据集A或B）的记录。
2. **Shuffle 阶段**：
    - Shuffle 过程将 Map 输出的中间键值对根据键进行排序和分组。所有共同键的值都会被集中到一起。
3. **Reduce 阶段**：
    
    - 在 Reduce 阶段，每个 Reduce 任务接收到了包含相同键的所有值的列表。这个列表中会同时包含来自数据集A和B的记录。
    - Reduce 函数然后遍历这些值，根据键值对中的标识将来自数据集A和B的记录分开，并执行连接操作。
    - 连接后的结果会被写出到最终的输出文件中。

Reduce side join 在处理大型分布式数据集时非常强大，但也有其缺点。它需要大量的数据在网络中移动（即数据洗牌），这可能会导致较高的网络传输开销，并且如果连接的键有很多重复值，也可能会在 Reduce 阶段产生瓶颈。
### Similarity Check
**相似度量**：距离越小 = 相似度越高
#### Jaccard Similarity
- Jaccard Similarity
$$
S_{Jaccard}(A, B) = \frac {|A\cap B|} {|A \cup B|}
$$
![image.png](https://images.wu.engineer/images/2023/11/23/202311231418863.png)
- Jaccard Distance
$$
d_{Jaccard}(A,B) = 1 - s_{Jaccard}(A,B)
$$
### Similarity Document Check
#### Step 1: Shingling
分词：这一步将文档转换为一组短语（称为“shingles”或“k-grams”）。每个shingle通常是文档中连续的k个项（可以是字、词或字符）。例如，对于句子“The quick brown fox jumps over the lazy dog”，如果我们使用2-grams（bigrams）作为shingles，那么一个可能的shingle集合包括{"The quick", "quick brown", "brown fox", ...}。这一步的目的是创建文档的特征集，以便于比较。
对于两个文档，我们使用一个矩阵将两个文档$D_1$, $D_2$中的分词表示出来，1代表存在与文档中，0则没有
![image.png](https://images.wu.engineer/images/2023/11/23/202311231428517.png)
#### Step 2: Min-Hashing
最小哈希：这一步的目的是将上一步得到的shingle集合转换为文档的“签名”（signature），这些签名在压缩数据的同时保留了文档间的相似性信息。签名是一个较短的数据块，它代表了文档内容的摘要。Min-hashing算法通过对每个文档的shingle集合使用哈希函数，将其转换为一个较短的哈希值序列（即签名），而且这一转换过程保留了原始shingle集合间的相似度结构。具有相同或相似签名的文档被认为是“候选对”（candidate pairs），这意味着它们很可能是近似重复的文档。
### NoSQL Pros and Cons
相对于传统关系型数据库，NoSQL数据库的**优点**包括：
- **可扩展性**：更容易扩展到多个服务器。
- **灵活性**：可以适应多变的数据模型和不断变化的数据类型。
- **高性能**：特别是在处理大量数据和高并发请求时。
NoSQL数据库的**缺点**可能包括：
- **一致性**：可能牺牲事务的严格一致性来获取性能和可扩展性。
- **复杂的数据关联**：对于需要复杂关联的数据，关系型数据库可能更加适合。
### BASE and ACID
- ACID
	- Relational DBMS provide stronger (ACID) guarantees
	- **ACID**是传统关系型数据库的设计理念，它强调的是数据操作的可靠性和一致性：
		1. **原子性（Atomicity）**：事务中的所有操作都是一个不可分割的工作单位，要么全部完成，要么全部不做。
		2. **一致性（Consistency）**：事务执行结果必须使数据库从一个一致性状态转变到另一个一致性状态。
		3. **隔离性（Isolation）**：并发执行的事务之间不会互相影响。
		4. **持久性（Durability）**：一旦事务提交，其所做的修改将永久保存在数据库中。
- BASE
	- In many NoSQL system provide weaker "BASE" approach
	- **BASE**则是许多NoSQL数据库系统遵循的理念，它更强调系统的可用性和容错性：
		1. **基本可用（Basically Available）**：系统保证可用性，但可能因为响应时间的延迟或系统功能的减少而不是完全可用。
		2. **软状态（Soft state）**：系统的状态可能会随时间而改变，即使没有输入，系统状态仍然有可能变化（例如，由于数据复制而导致的状态变化）。
		3. **最终一致性（Eventual consistency）**：系统保证，如果没有新的更新操作，数据最终将达到一致状态。
	- Pros：
		1. **高可用性**：
		    - NoSQL数据库通常可以在部分系统故障时继续工作，它们避免了单点故障，提供了更高的可用性。
		2. **弹性扩展**：
		    - NoSQL数据库设计之初就考虑到了水平扩展，它们可以通过添加更多的服务器来处理更多的数据和负载，而不需要昂贵的单体服务器。
		3. **灵活性**：
		    - 无模式或者灵活模式的数据存储，使得NoSQL数据库可以轻松应对结构变化和不同类型的数据。
		4. **性能**：
		    - 在某些操作上，尤其是那些不需要复杂事务支持的操作上，NoSQL数据库可以提供更好的性能。
	- Cons：
		1. **一致性问题**：
		    - 最终一致性模型意味着在数据同步过程中可能存在不一致性的时间窗口，这可能不适合对实时一致性要求很高的应用。
		2. **复杂性**：
		    - 开发者可能需要在应用程序层面处理一致性问题，这可能增加应用程序逻辑的复杂性。
		3. **无事务性**：
		    - 传统的事务特性（如ACID）在很多NoSQL数据库中是不支持的，或者只有部分支持，这对于需要强事务性的系统来说是一个限制。
		4. **数据冗余**：
		    - 为了提供高可用性和性能，NoSQL数据库可能会存储数据副本，这可能导致数据存储的冗余
### NoSQL Types
- **键值存储（Key-Value Stores）**：
    - 最简单的NoSQL数据库，以键值对的形式存储数据。
    - 键值存储的一些特点包括：
        1. **无模式**：键值存储通常不具备固定的模式或结构，数据可以以任何形式存储为值，如字符串、JSON、BLOB等。
        2. **无关联**：它们不提供原生的方式来直接关联不同的键值对或模仿SQL中的表间连接。关系必须由应用逻辑来管理。
        3. **单一的数据集合**：虽然某些键值存储系统可能允许你创建类似于“表”的不同命名空间或数据集合，但这些通常不提供连接功能。
        4. **自定义索引**：在键值存储中，创建复杂索引需要应用层面的设计，比如通过维护一个特殊的键，它的值包含了需要被索引的数据项的键的列表。
    - **键值存储的优势**:
        1. **性能**：键值存储提供非常快速的读写能力，因为它们通过键直接访问值，通常这些操作可以在O(1)时间内完成。
        2. **可扩展性**：键值存储通常设计为易于水平扩展，能够处理更多的负载通过简单地增加更多的节点。
        3. **简单性**：由于其简单的数据模型，键值存储通常更易于设置和维护。
        4. **灵活性**：键值存储不需要预定义的模式，所以你可以随意存储不同结构的数据。
    - 例子：Redis, Amazon DynamoDB, Riak。

- **文档存储（Document Stores）**：
    - 以下是文档存储NoSQL数据库的一些关键特点：
        1. **灵活的数据模型**：文档可以包含嵌套的数据结构，如数组和子文档。由于没有固定的模式，文档的结构可以动态更改。
        2. **自描述性**：文档存储通常是自描述的，意味着数据结构描述包含在文档本身中，这使得数据的解析和理解变得直观。
        3. **查询能力**：大多数文档数据库提供了强大的查询语言，允许用户执行复杂的搜索、聚合和过滤操作。
        4. **索引**：为了提高查询性能，文档数据库支持在一个或多个文档的属性上建立索引。
        5. **扩展性**：文档数据库也设计为易于水平扩展，允许通过增加更多的服务器来增加数据库的容量和吞吐量。
        6. **API接口**：文档数据库通常提供丰富的API用于交互，这些API可以是RESTful的，也可以是数据库专有的查询语言。
    - 存储半结构化数据的文档，通常是JSON或XML格式。
    - 文档数据库的一个主要优势在于其灵活性。它们允许开发者在不需要预先定义表结构的情况下存储和查询数据，这对于快速开发和迭代、以及处理非结构化或半结构化数据非常有利。
    - 然而，文档数据库也有其局限性，如它们可能不支持像传统SQL数据库那样复杂的事务管理，而且当涉及到多个文档或集合时，维护数据一致性可能会更加复杂。
    - 例子：MongoDB, CouchDB, Firestore。

- **宽列存储（Wide-Column Stores）**：
    - 以列族为中心存储数据，允许存储大量数据。
    - 以下是宽列存储的一些核心特点：
        1. **列族（Column Families）**：
            - 数据被存储在列族中，每个列族是一个容器，存储着相关的列。
            - 列族内的列可以在每一行中不同，允许每行有不同的列数和类型，这带来了极大的灵活性。
        2. **行键（Row Keys）**：
            - 每一行由一个唯一的行键（Row Key）标识，可以用来快速访问和检索数据。
        3. **动态列**：
            - 每行可以有数千甚至数百万列，列可以在运行时动态地增加到任何行中，不需要预先定义模式。
        4. **可扩展性**：
            - 宽列存储设计用于水平扩展，可以通过增加更多的服务器节点来提高容量和吞吐量。
        5. **优化读/写性能**：
            - 通过将相关数据存储在相同的列族中，宽列存储可以优化数据的读取和写入性能。
        6. **分布式架构**：
            - 它们通常自带分布式架构，能够处理大规模数据分布在多个物理位置。
        - 例子：Apache Cassandra, HBase, Google Bigtable。

- **图形数据库（Graph Databases）**：
	- 使用图结构存储实体以及实体之间的关系，适合复杂的关系数据。
	- **核心概念**：
	    1. **节点（Nodes）**：
	        - 节点代表实体，如人、业务、账户、计算机等。
	        - 每个节点可以有一个或多个标签（Labels）来表示不同的类别或类型。
	        - 节点可以包含多个属性（键值对），用以存储关于实体的信息。
	    2. **边（Edges）**：
	        - 边代表节点之间的关系。
	        - 每条边都有一个类型，表明连接的节点之间的关系性质，如“朋友”、“属于”或“访问”。
	        - 边也可以有属性，提供有关关系的更多信息，如权重、成本、距离等。
	    3. **属性（Properties）**：
	        - 节点和边都可以有属性，这些属性以键值对的形式存在。
	        - 属性为图数据添加了丰富的语义。
	    4. **索引（Indexes）**：
	        - 图形数据库通常支持通过索引来加速对节点和边的查询。
	- **图形数据库的特点**：
		1. **关系优先**：图形数据库将关系作为一等公民，这与其他数据库系统不同，在那里关系通常是通过外键或特殊的索引来表示的。
		2. **性能**：对于深度连接查询和复杂的关系网络，图形数据库可以提供卓越的性能。
		3. **灵活性**：图结构的自然灵活性使得添加新的关系和节点不需要更改现有的数据模式。
		4. **直观性**：图形数据库的结构使得数据模型和现实世界的网络直观对应，方便理解和查询。
	- 例子：Neo4j, JanusGraph, Amazon Neptune。

- **矢量数据库（Vector Databases）**
	- 矢量数据库（Vector Databases）是专门设计来存储和查询矢量空间数据的数据库系统。在这个上下文中，“矢量”通常指的是多维的数值数组，它们代表了数据点在特定的特征空间中的位置。这种类型的数据库在处理大规模机器学习和人工智能任务中尤为重要，尤其是在执行相似性搜索时。
	- **核心概念**：
		1. **特征向量（Feature Vectors）**：
		    - 在机器学习和搜索领域，数据项经常被转换成特征向量，这些特征向量表示了数据项的特性或属性。
		2. **相似性搜索（Similarity Search）**：
		    - 矢量数据库的主要功能之一是快速找到与给定查询向量相似的向量。相似性度量通常使用余弦相似度、欧几里得距离等方法。
		3. **索引和优化**：
		    - 为了高效地进行相似性搜索，矢量数据库使用多种索引和优化技术，如树结构、哈希技术或分区策略。
	- **矢量数据库的特点**：
		1. **高效的搜索性能**：
		    - 矢量数据库能够在高维空间中快速执行k最近邻（k-NN）搜索，这对于实时推荐系统、图像或视频检索等是至关重要的。
		2. **大规模数据处理**：
		    - 它们可以处理数以亿计的向量，并且在这样的规模上仍能保持查询的响应时间。
		3. **机器学习集成**：
		    - 矢量数据库经常与机器学习模型和流程紧密集成，以便直接利用模型生成的特征向量。
### Consistency
- **Strong consistency**
	- 任何数据的更新操作完成后，后续的任何读取操作都将**立即看到这个更新**。换句话说，系统确保所有节点上的数据在**任何时间点都是一致的**。
	- 这通常意味着系统需要在更新数据时进行一定的协调，以确保所有的复制节点都同步更新，这可能会导致写操作延迟增加。
	- 强一致性模型适合对数据一致性要求极高的场景，如金融交易系统。
- **Eventual consistency**
	- 数据的更新**不需要立即反映到所有节点上**。系统只保证如果没有新的更新发生，那么最终所有的复制节点将会达到一个一致的状态。
	- 这意味着在达到一致性状态之前，不同的节点可**能会看到不同版本的数据**，从而允许系统在某个时间点上存在**数据不一致**的情况。
	- 最终一致性模型提供了**更高的可用性和分区容错性，但牺牲了实时一致性保证**。
	- 这种模型适合对可用性要求高，但可以容忍短时间内数据不一致的应用，如社交网络中的时间线更新。
- **Duplication (Denormalisation)**
	- 去规范化（Denormalization）是数据库优化的一个过程，特别是在关系型数据库的上下文中。高度规范化可能导致性能问题，因为复杂的查询可能需要多个表之间的连接操作，这在大型数据库中可能会非常耗时。去规范化涉及减少数据库的规范化级别，通常通过合并表格、添加冗余数据或组合字段来实现。其主要目的是提高数据库的查询性能，尤其是在大数据量和复杂查询的情况下。
	- 去规范化的策略包括：
		1. **添加冗余列**：在一个表中包含来自另一个表的数据，以避免连接操作。
		2. **合并表**：将多个相关的表合并为一个表，以减少查询中的连接数量。
		3. **预计算聚合**：存储计算结果（如总和、平均值等）而不是在每次查询时都重新计算。
		4. **创建冗余索引**：创建额外的索引来加速查询，即使这些索引会占用更多的存储空间。
	- 去规范化的缺点是可能导致数据更新、插入和删除操作的复杂性增加，因为需要维护额外的冗余数据的一致性。此外，它也增加了存储需求，因为相同的数据会在多个地方存储副本。
### Data Partitioning
- Table Partitioning
- Horizontal Partitioning
- Range Partitioning
- Hash Partitioning
- Consistent Hashing
### MongoDB
- Routers
- Config Server
- Replica Sets
- Replication


## Spark

## Streaming

## Graph

## Big Data System
